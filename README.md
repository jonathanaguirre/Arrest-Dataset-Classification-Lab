# Arrest Prediction - Classification with Logistic Regression and XGBoost

This project is part of my hands-on journey through the **LinkedIn Learning + Wolfram Research Machine Learning Certificate**. It explores supervised learning using real-world stop-and-search data to predict whether a police stop will lead to an arrest.

## ğŸ¯ Objective  
Use classification algorithms to build a model that predicts arrest likelihood based on features like age, gender, time of day, and location.

## ğŸ§  Models Used  
- Logistic Regression  
- XGBoost (Python API)

## ğŸ§° Tools & Technologies  
- JupyterLab (Web-based)  
- Python 3.8 (Pyodide Kernel or standard kernel)  
- Pandas, Scikit-learn, XGBoost  
- Matplotlib or Plotly (for visualization)

## ğŸ“Š Dataset  
- Dataset: PLACERHOLDER  
- Features: PLACEHOLDER  
- Target: PLACEHOLDER

## âš™ï¸ ML Workflow  
1. **Data Preprocessing**  
   - KNN Imputation  
   - One-hot Encoding  
   - Outlier Removal  
   - Feature Correlation Analysis  

2. **Model Training**  
   - Logistic Regression using scikit-learn  
   - XGBoost Classifier (Python API)

3. **Model Evaluation**  
   - AUC (Area Under the Curve)  
   - Accuracy, Precision, Recall, F1-Score  
   - Confusion Matrix  
   - Output: Arrest Probability Score  

4. **Model Inference (Local)**  
   - Input new data into the trained model within the notebook  
   - Generate arrest probability scores directly

## ğŸ”„ Example Inference  
> Input: Gender=Male, Age=25, Time=2PM, Ethnicity=White, Location=XYZ  
> Output: `0.71` (71% chance of arrest)

## ğŸ“ Project Structure  
- `notebooks/` â€“ Jupyter Notebooks for each stage (preprocessing, training, evaluation, inference)  
- `data/` â€“ Raw and cleaned datasets  
- `models/` â€“ Saved model files (`.pkl` or `.json`)  
- `outputs/` â€“ Charts, confusion matrices, metrics reports

## âœ… Next Steps  
- Add SHAP or LIME for model explainability  
- Evaluate model fairness across demographics  
- Convert to U.S.-based dataset for further localization
